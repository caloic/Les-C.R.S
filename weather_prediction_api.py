from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialiser Flask
app = Flask(__name__)
CORS(app)  # Permettre les requ√™tes cross-origin

# Variables globales pour les mod√®les
models = {}


def load_models():
    """
    Charge les mod√®les entra√Æn√©s et les m√©tadonn√©es
    """
    global models

    model_dir = 'ml_models'

    try:
        # Charger les mod√®les
        models['temp_model'] = joblib.load(os.path.join(model_dir, 'temperature_model.pkl'))
        models['humid_model'] = joblib.load(os.path.join(model_dir, 'humidity_model.pkl'))
        models['scaler'] = joblib.load(os.path.join(model_dir, 'scaler.pkl'))

        # Charger les m√©tadonn√©es
        with open(os.path.join(model_dir, 'model_metadata.json'), 'r') as f:
            models['metadata'] = json.load(f)

        logger.info("Mod√®les charg√©s avec succ√®s")
        return True
    except Exception as e:
        logger.error(f"Erreur lors du chargement des mod√®les: {str(e)}")
        return False


def prepare_features(weather_data, historical_data=None):
    """
    Pr√©pare les features pour la pr√©diction √† partir des donn√©es m√©t√©o actuelles
    """
    try:
        # Cr√©er un DataFrame avec les donn√©es actuelles
        current_data = {
            '2 metre temperature': float(weather_data.get('temperature', 20)),
            '2 metre relative humidity': float(weather_data.get('humidity', 60)),
            '10m wind speed': float(weather_data.get('wind_speed', 10)),
            'Total precipitation': float(weather_data.get('precipitation', 0))
        }

        # Si on a des donn√©es historiques, les utiliser pour les features de d√©calage
        if historical_data and len(historical_data) >= 24:
            # Convertir en DataFrame
            hist_df = pd.DataFrame(historical_data)

            # Ajouter les donn√©es actuelles
            current_df = pd.DataFrame([current_data])
            df = pd.concat([hist_df, current_df], ignore_index=True)

            # Cr√©er les features de d√©calage pour la derni√®re ligne
            for col in current_data.keys():
                if col in df.columns:
                    current_data[f'{col}_lag_1h'] = df[col].iloc[-2] if len(df) > 1 else current_data[col]
                    current_data[f'{col}_lag_3h'] = df[col].iloc[-4] if len(df) > 3 else current_data[col]
                    current_data[f'{col}_lag_6h'] = df[col].iloc[-7] if len(df) > 6 else current_data[col]
                    current_data[f'{col}_ma_6h'] = df[col].tail(6).mean()
                    current_data[f'{col}_ma_24h'] = df[col].tail(24).mean()
        else:
            # Pas de donn√©es historiques, utiliser les valeurs actuelles
            for col in list(current_data.keys()):
                current_data[f'{col}_lag_1h'] = current_data[col]
                current_data[f'{col}_lag_3h'] = current_data[col]
                current_data[f'{col}_lag_6h'] = current_data[col]
                current_data[f'{col}_ma_6h'] = current_data[col]
                current_data[f'{col}_ma_24h'] = current_data[col]

        # Ajouter les features temporelles
        now = datetime.now()
        current_data['hour'] = now.hour
        current_data['day_of_week'] = now.weekday()

        # Cr√©er un DataFrame avec toutes les features dans le bon ordre
        feature_cols = models['metadata']['feature_columns']
        features_df = pd.DataFrame([current_data])

        # S'assurer que toutes les colonnes sont pr√©sentes
        for col in feature_cols:
            if col not in features_df.columns:
                features_df[col] = 0  # Valeur par d√©faut

        # R√©ordonner les colonnes
        features_df = features_df[feature_cols]

        return features_df

    except Exception as e:
        logger.error(f"Erreur lors de la pr√©paration des features: {str(e)}")
        return None


@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint de v√©rification de sant√©"""
    return jsonify({
        'status': 'healthy',
        'models_loaded': bool(models),
        'timestamp': datetime.now().isoformat()
    })


@app.route('/predict', methods=['POST'])
def predict():
    """
    Endpoint principal pour obtenir des pr√©dictions m√©t√©o

    Format de requ√™te attendu:
    {
        "current_weather": {
            "temperature": 20,
            "humidity": 65,
            "wind_speed": 15,
            "precipitation": 0
        },
        "historical_data": [...]  // Optionnel
    }
    """
    try:
        # V√©rifier que les mod√®les sont charg√©s
        if not models:
            return jsonify({
                'success': False,
                'error': 'Mod√®les non charg√©s'
            }), 500

        # R√©cup√©rer les donn√©es de la requ√™te
        data = request.get_json()

        if not data or 'current_weather' not in data:
            return jsonify({
                'success': False,
                'error': 'Donn√©es m√©t√©o actuelles requises'
            }), 400

        # Pr√©parer les features
        features_df = prepare_features(
            data['current_weather'],
            data.get('historical_data', None)
        )

        if features_df is None:
            return jsonify({
                'success': False,
                'error': 'Erreur lors de la pr√©paration des donn√©es'
            }), 500

        # Normaliser les features
        features_scaled = models['scaler'].transform(features_df)

        # Faire les pr√©dictions
        temp_pred = models['temp_model'].predict(features_scaled)[0]
        humid_pred = models['humid_model'].predict(features_scaled)[0]

        # S'assurer que les pr√©dictions sont dans des plages valides
        temp_pred = max(-50, min(60, temp_pred))
        humid_pred = max(0, min(100, humid_pred))

        # Calculer l'intervalle de confiance (approximatif)
        temp_std = 2.5  # √âcart-type approximatif bas√© sur les performances du mod√®le
        humid_std = 5.0

        response = {
            'success': True,
            'predictions': {
                'temperature': {
                    'value': round(float(temp_pred), 1),
                    'unit': '¬∞C',
                    'confidence_interval': {
                        'lower': round(float(temp_pred - temp_std), 1),
                        'upper': round(float(temp_pred + temp_std), 1)
                    }
                },
                'humidity': {
                    'value': round(float(humid_pred)),
                    'unit': '%',
                    'confidence_interval': {
                        'lower': round(max(0, float(humid_pred - humid_std))),
                        'upper': round(min(100, float(humid_pred + humid_std)))
                    }
                },
                'horizon': '3 hours',
                'timestamp': datetime.now().isoformat()
            },
            'model_info': {
                'type': models['metadata']['model_type'],
                'training_date': models['metadata']['training_date'],
                'metrics': models['metadata']['metrics']
            }
        }

        return jsonify(response)

    except Exception as e:
        logger.error(f"Erreur lors de la pr√©diction: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/batch_predict', methods=['POST'])
def batch_predict():
    """
    Endpoint pour pr√©dire plusieurs emplacements √† la fois
    """
    try:
        data = request.get_json()

        if not data or 'locations' not in data:
            return jsonify({
                'success': False,
                'error': 'Liste de localisations requise'
            }), 400

        predictions = []

        for location in data['locations']:
            # Pr√©parer les features pour chaque localisation
            features_df = prepare_features(
                location.get('current_weather', {}),
                location.get('historical_data', None)
            )

            if features_df is not None:
                # Normaliser et pr√©dire
                features_scaled = models['scaler'].transform(features_df)
                temp_pred = models['temp_model'].predict(features_scaled)[0]
                humid_pred = models['humid_model'].predict(features_scaled)[0]

                predictions.append({
                    'location_id': location.get('id', 'unknown'),
                    'location_name': location.get('name', 'Unknown'),
                    'temperature': round(float(temp_pred), 1),
                    'humidity': round(float(humid_pred))
                })

        return jsonify({
            'success': True,
            'predictions': predictions,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"Erreur lors de la pr√©diction batch: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/model_info', methods=['GET'])
def model_info():
    """
    Retourne des informations sur les mod√®les charg√©s
    """
    if not models:
        return jsonify({
            'success': False,
            'error': 'Mod√®les non charg√©s'
        }), 500

    return jsonify({
        'success': True,
        'metadata': models['metadata'],
        'status': 'operational',
        'timestamp': datetime.now().isoformat()
    })


if __name__ == '__main__':
    # Charger les mod√®les au d√©marrage
    if load_models():
        print("‚úÖ API de pr√©diction m√©t√©o d√©marr√©e!")
        print("üìç Endpoints disponibles:")
        print("   - POST /predict : Pr√©diction pour une localisation")
        print("   - POST /batch_predict : Pr√©dictions pour plusieurs localisations")
        print("   - GET /model_info : Informations sur les mod√®les")
        print("   - GET /health : V√©rification de sant√©")

        # D√©marrer le serveur
        app.run(host='0.0.0.0', port=5000, debug=True)
    else:
        print("‚ùå Erreur: Impossible de charger les mod√®les")
        print("Assurez-vous d'avoir ex√©cut√© train_weather_model.py d'abord")